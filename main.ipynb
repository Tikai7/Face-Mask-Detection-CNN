{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading & Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Temp = open('X_Data','rb')\n",
    "X_Data = pickle.load(X_Temp)\n",
    "\n",
    "Y_Temp = open('Y_Data','rb')\n",
    "Y_Data = pickle.load(Y_Temp)\n",
    "\n",
    "X_Data = np.array(X_Data)\n",
    "Y_Data = np.array(Y_Data)\n",
    "\n",
    "print(X_Data.shape)\n",
    "print(Y_Data.shape)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_Data,Y_Data,test_size=0.2,random_state=42,shuffle=True)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#for X,y in zip(X_test,y_test):\n",
    "    #plt.imshow(X,label=y)\n",
    "    #print(y)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     zoom_range = (0.95,0.99),\n",
    "#     rotation_range=25,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=0.2\n",
    "# )\n",
    "\n",
    "# datagen.fit(X_train,augment=True)\n",
    "\n",
    "# print(X_train.mean())\n",
    "# print(X_train.std())\n",
    "# print(X_train[0])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0],-1))\n",
    "X_test = scaler.transform(X_test.reshape(X_test.shape[0],-1))\n",
    "\n",
    "X_train = X_train.reshape(-1,224,224,1) \n",
    "X_test = X_test.reshape(-1,224,224,1) \n",
    "\n",
    "print(X_train.mean())\n",
    "print(X_train.std())\n",
    "\n",
    "#for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    #for i in range(0, 9):\n",
    "        #plt.subplot(330 + 1 + i)\n",
    "        #plt.imshow(X_batch[i])\n",
    "        #plt.show()\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ Bloc MobileNet -----------------------\n",
    "\n",
    "class TikaiNetBlock(layers.Layer):\n",
    "    \n",
    "    def __init__(self,filters,strides):\n",
    "        super(TikaiNetBlock,self).__init__()\n",
    "        self.dw = layers.DepthwiseConv2D(kernel_size=3,strides=strides,padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.bn_2 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.relu_2 = layers.ReLU()\n",
    "        self.conv_2 = layers.Conv2D(filters=filters,kernel_size=1,strides=1)\n",
    "    \n",
    "    def call(self,X):\n",
    "        \n",
    "        X = self.dw(X)\n",
    "        X = self.bn(X)\n",
    "        X = self.relu(X)\n",
    "\n",
    "        X = self.conv_2(X)\n",
    "        X = self.bn_2(X)\n",
    "        X = self.relu_2(X)\n",
    "\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling & Training & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32,3,2,padding=\"same\",input_shape=(224,224,1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(TikaiNetBlock(64,1))\n",
    "model.add(TikaiNetBlock(128,2))\n",
    "model.add(TikaiNetBlock(128,1))\n",
    "model.add(TikaiNetBlock(256,2))\n",
    "model.add(TikaiNetBlock(256,1))\n",
    "model.add(TikaiNetBlock(512,2))\n",
    "for _ in range(5):\n",
    "    model.add(TikaiNetBlock(512,1))\n",
    "\n",
    "model.add(TikaiNetBlock(1024,2))\n",
    "model.add(TikaiNetBlock(1024,1))\n",
    "model.add(layers.AveragePooling2D(pool_size=7,strides=1))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer= Adam(),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "BS = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# history = model.fit(\n",
    "#     datagen.flow(X_train, y_train, batch_size=32,\n",
    "#     subset='training'),\n",
    "#     validation_data=datagen.flow(X_train, y_train,\n",
    "#     batch_size=8, subset='validation'),\n",
    "#     epochs=EPOCHS\n",
    "# )\n",
    "history = model.fit(X_train,y_train,batch_size=BS,epochs=EPOCHS,validation_data=(X_test,y_test))\n",
    "                    \n",
    "model.save(\"mask_model\",save_format=\"tf\") \n",
    "#A = model.evaluate(X_test,y_test)\n",
    "#print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "val_loss_curve =  history.history[\"val_loss\"]\n",
    "val_acc_curve = history.history[\"val_accuracy\"]\n",
    "acc_curve = history.history[\"accuracy\"]\n",
    "loss_curve = history.history[\"loss\"]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(val_acc_curve,c=\"red\",label=\"Val_Acc\")\n",
    "plt.plot(acc_curve,c=\"blue\",label=\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(val_loss_curve,c=\"red\",label=\"Val_Loss\")\n",
    "plt.plot(loss_curve,c=\"blue\",label=\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = model.predict(X_test[600].reshape(1,224,224,1))\n",
    "print(A*100)\n",
    "plt.imshow(X_test[600])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
  },
  "kernelspec": {
   "display_name": "Python 3.8.4rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
